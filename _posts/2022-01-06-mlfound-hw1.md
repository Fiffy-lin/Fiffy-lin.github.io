---
layout: post
title: "机器学习基石-作业1"
subtitle: ""
date: 2022-01-06
author: "Fiffy"
header-img: "img/post-bg-2015.jpg"
tags: ["Course","机器学习基石"]
---

# The Learning Problem

1. Which of the following problem is suited for machine learning if there is assumed to be enough associated data? Choose the correct answer; explain how you can possibly use machine learning to solve it.

   - [a] predicting the winning number of the next invoice lottery 
   - [b] calculating the average score of 500 students 
   - [c] identifying the exact minimal spanning tree of a graph 
   - [d] ranking mango images by the quality of the mangoes
   - [e] none of the other choices

   [a] is wrong, as lottery is totally random.

   [b] [c] doesn't need ml algorithms.

   [d] is okay.

   Choose [d]

2. Which of the following describes an machine learning approach to build a system for spam detection? Choose the correct answer; explain briefly why you think other choices are not machine learning.

   - [a] flip 3 fair coins; classify the email as a spam if at least 2 of them are heads 
   - [b] forward the email to 3 humans; classify the email as a spam if at least 2 of them believe so 
   - [c] produce a list of words for spams by 3 humans; classify the email as a spam if the email contains more than 10 words from the list 
   - [d] get a data set that contains spams and non-spams, for all words in the data set, let the machine calculate the ratio of spams per word; produce a list of words that appear more than 5 times and are of the highest 20% ratio; classify the email as a spam iff the email contains more than 10 words from the list 
   - [e] get a data set that contains spams and non-spams, for all words in the data set, let the machine decide its “spam score”; sum the score up for each email; let the machine optimize a threshold that achieves the best precision of spam detection; classify the email as a spam iff the email is of score more than the threshold

   [a] is random guessing.

   [b] is human labeling.

   [c] [d] is rule based. Ratio percentages and threshold of appearance is not learned.

   [e] is okay.

   Choose [e].

# Perceptron Learning Algorithm

1. Dr. Short scales down all xn (including the x0 within) linearly by a factor of 4 before running PLA. How does the worst-case speed of PLA (in terms of the bound on page 16 of lecture 2) change after scaling? Choose the correct answer; explain your answer.

   - [a] 4 times smaller (i.e. faster) 
   - [b] 2 times smaller 
   - [c] √ 2 times smaller 
   - [d] unchanged 
   - [e] √ 2 times larger (i.e. slower)

   

   



